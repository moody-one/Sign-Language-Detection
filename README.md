# ğŸ¤Ÿ Sign Language Detection with Mediapipe & TensorFlow

A real-time sign language recognition system using hand landmarks via Mediapipe and a custom-trained neural network. This project helps detect and classify static hand gestures (signs) using live webcam input.

## ğŸ“ Files Overview
- `collect_sign_data.py` â€” Capture and save hand landmarks with labels.
- `train_sign_model.py` â€” Train the classification model using the collected data.
- `sign_language_model.h5` â€” Trained Keras model file.
- `label_map.pkl` â€” Mapping of gesture labels to class indices.
- `landmark_data.csv` â€” Collected landmark dataset.
- `test_sign_model.py` â€” Run the trained model in real time using your webcam.

## ğŸ› ï¸ Tech Stack
- Python
- Mediapipe
- OpenCV
- TensorFlow / Keras

## ğŸ”§ How to Run
1. Run `collect_sign_data.py` to gather sign samples.
2. Train using `train_sign_model.py`.
3. Test live with `test_sign_model.py`.

## ğŸ“Œ Notes
Make sure your webcam is connected. Use a plain background and good lighting for best results.

---

Contributions and feedback are welcome!
